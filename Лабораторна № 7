{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dima200206/-2/blob/main/%D0%9B%D0%B0%D0%B1%D0%BE%D1%80%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D0%B0%20%E2%84%96%207\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ЛАБОРАТОРНА РОБОТА 7\n",
        "Тема: РЕКОМЕНДАЦІЙНІ СИСТЕМИ\n",
        "Завдання 1.\n",
        "1. Завантажте датасет для рецензій (ml-100k) за допомогою бібліотеки\n",
        "Surprise.\n",
        "2. Виведіть перші 5 рядків завантаженого датасету.\n",
        "3. Реалізуйте два алгоритми для рекомендаційної системи на основі цього\n",
        "датасету. Можна вибрати будь-які алгоритми з бібліотеки Surprise.\n",
        "4. Використайте крос-валідацію для підбору оптимальних параметрів для\n",
        "обох алгоритмів.\n",
        "5. Оберіть найкращий алгоритм на основі середньої абсолютної помилки\n",
        "(MAE).\n",
        "6. Виведи рекомендації (10 фільмів) для конкретного користувача.\n",
        "\n"
      ],
      "metadata": {
        "id": "FDrD8FJb_YTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Завантажте датасет для рецензій (ml-100k) за допомогою бібліотеки Surprise.\n",
        "!pip install scikit-surprise\n",
        "\n",
        "from surprise import Dataset, Reader\n",
        "from surprise.model_selection import train_test_split, cross_validate, GridSearchCV\n",
        "from surprise import SVD, KNNBasic\n",
        "from surprise.accuracy import mae\n",
        "from collections import defaultdict\n",
        "\n",
        "# Завантаження датасету 'ml-100k'\n",
        "data = Dataset.load_builtin('ml-100k')\n",
        "\n",
        "# 2. Виведіть перші 5 рядків завантаженого датасету.\n",
        "# Перетворимо датасет в pandas DataFrame для виводу перших 5 рядків\n",
        "import pandas as pd\n",
        "\n",
        "raw_ratings = data.raw_ratings\n",
        "df = pd.DataFrame(raw_ratings, columns=['user_id', 'item_id', 'rating', 'timestamp'])\n",
        "print(\"Перші 5 рядків датасету:\")\n",
        "print(df.head())\n",
        "\n",
        "# 3. Реалізуйте два алгоритми для рекомендаційної системи на основі цього датасету.\n",
        "# SVD - один з популярних алгоритмів для рекомендацій\n",
        "# KNNBasic - алгоритм на основі сусідів\n",
        "\n",
        "# 4. Використайте крос-валідацію для підбору оптимальних параметрів для обох алгоритмів.\n",
        "\n",
        "# Розбиття даних на навчальну і тестову вибірки\n",
        "trainset, testset = train_test_split(data, test_size=0.25)\n",
        "\n",
        "# Алгоритм 1: SVD\n",
        "param_grid_svd = {'n_factors': [50, 100], 'n_epochs': [20, 30], 'lr_all': [0.005, 0.01]}\n",
        "gs_svd = GridSearchCV(SVD, param_grid_svd, measures=['mae'], cv=3)\n",
        "gs_svd.fit(data)\n",
        "print(\"Найкращі параметри для SVD: \", gs_svd.best_params['mae'])\n",
        "\n",
        "# Алгоритм 2: KNNBasic\n",
        "param_grid_knn = {'k': [20, 40], 'sim_options': {'name': ['cosine', 'pearson_baseline'], 'user_based': [True, False]}}\n",
        "gs_knn = GridSearchCV(KNNBasic, param_grid_knn, measures=['mae'], cv=3)\n",
        "gs_knn.fit(data)\n",
        "print(\"Найкращі параметри для KNNBasic: \", gs_knn.best_params['mae'])\n",
        "\n",
        "# 5. Оберіть найкращий алгоритм на основі середньої абсолютної помилки (MAE).\n",
        "algo_svd = gs_svd.best_estimator['mae']\n",
        "algo_knn = gs_knn.best_estimator['mae']\n",
        "\n",
        "# Тестування на тестовій вибірці\n",
        "algo_svd.fit(trainset)\n",
        "predictions_svd = algo_svd.test(testset)\n",
        "mae_svd = mae(predictions_svd)\n",
        "\n",
        "algo_knn.fit(trainset)\n",
        "predictions_knn = algo_knn.test(testset)\n",
        "mae_knn = mae(predictions_knn)\n",
        "\n",
        "if mae_svd < mae_knn:\n",
        "    best_algo = algo_svd\n",
        "    print(f\"SVD має кращу MAE: {mae_svd}\")\n",
        "else:\n",
        "    best_algo = algo_knn\n",
        "    print(f\"KNNBasic має кращу MAE: {mae_knn}\")\n",
        "\n",
        "# 6. Виведіть рекомендації (10 фільмів) для конкретного користувача.\n",
        "def get_top_n_recommendations(predictions, n=10):\n",
        "    top_n = defaultdict(list)\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        top_n[uid].append((iid, est))\n",
        "\n",
        "    # Сортування за передбаченими рейтингами\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "        top_n[uid] = user_ratings[:n]\n",
        "\n",
        "    return top_n\n",
        "\n",
        "# Вибираємо користувача (наприклад, user_id = 196)\n",
        "user_id = 196\n",
        "predictions = best_algo.test(testset)\n",
        "top_n = get_top_n_recommendations(predictions, n=10)\n",
        "\n",
        "print(f\"Рекомендовані фільми для користувача {user_id}:\")\n",
        "for movie_id, predicted_rating in top_n[user_id]:\n",
        "    print(f\"Фільм ID: {movie_id}, Прогнозований рейтинг: {predicted_rating}\")\n"
      ],
      "metadata": {
        "id": "8_Pjx6fHBOpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Завдання 2.\n",
        "1. Побудуйте власну рекомендаційну систему (приклад є в документації).\n",
        "Оцініть її.\n",
        "2. Отримайте рекомендацію для певного користувача."
      ],
      "metadata": {
        "id": "fT59tsMa_eCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Встановлюємо бібліотеку Surprise\n",
        "!pip install scikit-surprise\n",
        "\n",
        "# Імпортуємо необхідні компоненти з бібліотеки Surprise\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import train_test_split, cross_validate\n",
        "from surprise import accuracy\n",
        "from collections import defaultdict\n",
        "\n",
        "# 1. Завантажуємо власний датасет або використовуємо вбудований 'ml-100k'\n",
        "# Можна завантажити власні дані за допомогою класу Reader, але тут використаємо вбудований датасет.\n",
        "data = Dataset.load_builtin('ml-100k')\n",
        "\n",
        "# Розділяємо дані на навчальну та тестову вибірки\n",
        "trainset, testset = train_test_split(data, test_size=0.25)\n",
        "\n",
        "# Використовуємо алгоритм SVD для побудови рекомендаційної системи\n",
        "algo = SVD()\n",
        "\n",
        "# Тренуємо модель на навчальній вибірці\n",
        "algo.fit(trainset)\n",
        "\n",
        "# Оцінюємо модель на тестовій вибірці\n",
        "predictions = algo.test(testset)\n",
        "\n",
        "# Виводимо середню абсолютну помилку (MAE) для оцінки моделі\n",
        "mae = accuracy.mae(predictions)\n",
        "\n",
        "# Можна також використати крос-валідацію для більш точної оцінки\n",
        "cv_results = cross_validate(algo, data, measures=['MAE', 'RMSE'], cv=5, verbose=True)\n",
        "\n",
        "# 2. Отримуємо рекомендацію для певного користувача.\n",
        "# Напишемо функцію, яка згенерує рекомендації для користувача.\n",
        "\n",
        "def get_top_n_recommendations(predictions, n=10):\n",
        "    # Створюємо словник для зберігання рекомендацій\n",
        "    top_n = defaultdict(list)\n",
        "\n",
        "    # Додаємо фільми до словника для кожного користувача\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        top_n[uid].append((iid, est))\n",
        "\n",
        "    # Сортуємо фільми за передбачуваними рейтингами та беремо топ-n\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "        top_n[uid] = user_ratings[:n]\n",
        "\n",
        "    return top_n\n",
        "\n",
        "# Припустимо, що ми хочемо отримати рекомендації для користувача з ID = 196\n",
        "user_id = 196\n",
        "# Отримуємо передбачення для всіх фільмів\n",
        "predictions = algo.test(testset)\n",
        "# Отримуємо топ-10 рекомендацій для користувача\n",
        "top_n = get_top_n_recommendations(predictions, n=10)\n",
        "\n",
        "# Виводимо 10 рекомендованих фільмів для користувача\n",
        "print(f\"Рекомендовані фільми для користувача {user_id}:\")\n",
        "for movie_id, predicted_rating in top_n[user_id]:\n",
        "    print(f\"Фільм ID: {movie_id}, Прогнозований рейтинг: {predicted_rating}\")\n"
      ],
      "metadata": {
        "id": "8IP7i1wVBl6T"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPh5amX57I+OWDDk0TyARkF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}