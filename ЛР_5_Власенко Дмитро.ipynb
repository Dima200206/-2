{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dima200206/-2/blob/main/%D0%9B%D0%A0_5_%D0%92%D0%BB%D0%B0%D1%81%D0%B5%D0%BD%D0%BA%D0%BE%20%D0%94%D0%BC%D0%B8%D1%82%D1%80%D0%BE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Лабораторна робота 5\n",
        "\n",
        "\n",
        "Завантажити датасет\n",
        "\n",
        "https://www.kaggle.com/datasets/gpiosenka/sports-classification\n",
        "\n",
        "Використовуючи трансферне навчання, побудувати модель для класифікації зображень.\n",
        "\n",
        "Вивести криві навчання, результати розпізнавання.\n",
        "Висновки.\n",
        "\n",
        "Зауваження VGG16 не використовувати.\n"
      ],
      "metadata": {
        "id": "BwHhQ0KC8kJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.utils import make_grid\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "# filter warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "A3hmm_Iw8pSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/kaggle/input/sports-classification/train'\n",
        "valid_dir = '/kaggle/input/sports-classification/valid'\n",
        "test_dir ='/kaggle/input/sports-classification/test'"
      ],
      "metadata": {
        "id": "4uZOJQVY8qDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((150, 150)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "uMED2_6o8qBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
        "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
        "valid_dataset = datasets.ImageFolder(valid_dir, transform=transform)"
      ],
      "metadata": {
        "id": "bW6UQr_w8p_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)"
      ],
      "metadata": {
        "id": "0moiWin78p8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(images, labels, class_names):\n",
        "    images = images.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    images = std * images + mean\n",
        "    images = np.clip(images, 0, 1)\n",
        "    plt.imshow(images)\n",
        "    plt.title(\", \".join([class_names[l] for l in labels]))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "m9x-x6Wr8p6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_loader.dataset.classes"
      ],
      "metadata": {
        "id": "nN1ueq7f8p3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "imshow(make_grid(images[:10], nrow=5), labels[:10], class_names)"
      ],
      "metadata": {
        "id": "wjdM9vqc8p1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of classes: {len(train_dataset.classes)}\")\n",
        "print(f\"Classes: {train_dataset.classes}\")\n",
        "print(f\"Training set size: {len(train_dataset)}\")\n",
        "print(f\"Validation set size: {len(valid_dataset)}\")\n",
        "print(f\"Test set size: {len(test_dataset)}\")\n",
        "\n",
        "class_counts = {class_name: 0 for class_name in train_dataset.classes}\n",
        "for _, label in train_dataset.samples:\n",
        "    class_counts[train_dataset.classes[label]] += 1\n",
        "\n",
        "print(\"\\nClass distribution in the training setі:\")\n",
        "for class_name, count in class_counts.items():\n",
        "    print(f\"{class_name}: {count}\")"
      ],
      "metadata": {
        "id": "j7m-2hIV8pyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 100)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "rA_yOI2Q8pv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "best_valid_loss = float('inf')\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "valid_losses = []\n",
        "valid_accuracies = []"
      ],
      "metadata": {
        "id": "OPyypt958ptF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_accuracy = correct / total\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Валідація\n",
        "    model.eval()\n",
        "    valid_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(valid_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    valid_loss /= len(valid_loader)\n",
        "    valid_accuracy = correct / total\n",
        "    valid_losses.append(valid_loss)\n",
        "    valid_accuracies.append(valid_accuracy)\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}:')\n",
        "    print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
        "    print(f'Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.4f}')\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'best_model_1.pth')"
      ],
      "metadata": {
        "id": "JT7EJktj8pqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_predictions(model, dataloader, class_names, num_images=5):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure(figsize=(15, 10))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size(0)):\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    plt.tight_layout()\n",
        "                    plt.show()\n",
        "                    return\n",
        "\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2 + 1, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title(f'Predicted: {class_names[preds[j]]}\\nTrue: {class_names[labels[j]]}')\n",
        "\n",
        "                # Денормалізація зображення для відображення\n",
        "                inv_normalize = transforms.Normalize(\n",
        "                    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
        "                    std=[1/0.229, 1/0.224, 1/0.225]\n",
        "                )\n",
        "                inp = inv_normalize(inputs.cpu()[j]).numpy().transpose((1, 2, 0))\n",
        "                inp = np.clip(inp, 0, 1)\n",
        "\n",
        "                plt.imshow(inp)\n",
        "\n",
        "    model.train(mode=was_training)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "UmvXOCDH8pn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_metrics(train_losses, train_accuracies, valid_losses, valid_accuracies):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_losses, 'b-', label='Training Loss')\n",
        "    plt.plot(epochs, valid_losses, 'r-', label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, train_accuracies, 'b-', label='Training Accuracy')\n",
        "    plt.plot(epochs, valid_accuracies, 'r-', label='Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "19I2Qgdi8pl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_preds = []\n",
        "all_labels = []\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "class_names = train_dataset.classes\n",
        "\n",
        "# Обчислення точності та F1\n",
        "test_accuracy = correct / total\n",
        "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "\n",
        "# Створення матриці помилок\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1ltwFSRH9o9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training_metrics(train_losses, train_accuracies, valid_losses, valid_accuracies)"
      ],
      "metadata": {
        "id": "TytcMNpi9o7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_predictions(model, test_loader, train_dataset.classes, 10)"
      ],
      "metadata": {
        "id": "D6h9BV_u9o4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Висновок: Під час виконання лабораторної роботи було успішно створено модель глибокого навчання на базі архітектури ResNet50 для класифікації зображень із датасету 100 Sports Image Classification. За допомогою бібліотек Python, зокрема TensorFlow та Keras, здійснено передобробку даних, завантажено модель із попередньо навченими вагами ImageNet та адаптовано її для класифікації 100 видів спорту.\n",
        "Модель досягла високої точності — 91% (0.91), що демонструє ефективність використання глибоких згорткових нейронних мереж у подібних завданнях. Отримані результати підтверджують доцільність вибору ResNet50 як базової архітектури для задач класифікації зображень із великою кількістю класів."
      ],
      "metadata": {
        "id": "QXciS16B9yWa"
      }
    }
  ]
}